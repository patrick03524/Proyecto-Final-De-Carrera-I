# -*- coding: utf-8 -*-
"""Globally and Locally Consistent Image Completion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15ObxHlUR3L9wZgPqA8cs_FjeyfDfapvQ

# Replica del artículo científico "*Globally and Locally Consistent Image Completion*"
## Alumno: Patrick Xavier Marquez Choque
## Curso: Proyecto Final de Carrera I
## Periodo: 2022-I

# Paso 1: Librerías Necesarias
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
# %matplotlib inline
import matplotlib.pyplot as plt

import torch
from torch import nn
from torch import optim
from torch.nn import functional as F
import torchvision
from torchvision import transforms
from torch.utils import data

from google.colab import drive
drive.mount('/content/drive')

!nvidia-smi

"""# Paso 2: Definición del Dataset a utilizar Cifar10"""

transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor()
])
dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)

train_split, val_split, test_split = 0.9, 0.05, 0.05
train_size = int(len(dataset) * train_split)
val_size = int(len(dataset) * val_split)
test_size = int(len(dataset) * test_split)

train, val, test = data.random_split(dataset, (train_size, val_size, test_size))
print(len(train), len(val), len(test))

"""# Paso 3: Definción de etapa de enmascaramiento para el conjunto de datos"""

def imshow(tensor):
    if len(tensor.shape) == 4:
        tensor = tensor[0]
    plt.imshow(tensor.cpu()[:3].permute(1, 2, 0))

print(type(train))
imshow(train[0][0])

def create_hole_mask(im_h, im_w, hole_h, hole_w):
    i = int((im_h - hole_h + 1) * np.random.random())
    j = int((im_w - hole_w + 1) * np.random.random())
    mask = torch.zeros((1, im_h, im_w))
    mask[0, i : i + hole_h, j : j + hole_w] = 1
    return mask, (i, i + hole_h, j, j + hole_w)

def create_hole_masks(N, im_h, im_w, hole_h, hole_w, same_size=True):
    if same_size:
        masks = [create_hole_mask(im_h, im_w, hole_h, hole_w) for _ in range(N)]
    else:
        h_min, h_max = hole_h
        w_min, w_max = hole_w
        hs, ws = np.random.randint(h_min, h_max, N), np.random.randint(w_min, w_max, N)
        masks = [create_hole_mask(im_h, im_w, h, w) for h, w in zip(hs, ws)]

    bounds = [mask[1] for mask in masks]
    masks = [mask[0] for mask in masks]
    masks = torch.cat(masks, dim=0)
    return masks.unsqueeze(1), bounds

create_hole_masks(2, 3, 3, 1, 1)

"""# Paso 4: Previsualización de nuestras máscaras"""

plt.imshow(create_hole_mask(32, 32, 5, 5)[0][0], cmap='gray')

imshow((1 - create_hole_mask(32, 32, 10, 10)[0][0]) * train[1000][0])

"""Paso 5: Implementación del Modelo Context-Encoder GAN(Generador)"""

class Flatten(nn.Module):
    def forward(self, input):
        return input.view(input.shape[0], -1)

class Unflatten(nn.Module):
    
    def __init__(self, shape):
        super(Unflatten, self).__init__()
        self.shape = shape
    
    def forward(self, X):
        return X.view(-1, *self.shape)

class Generator(nn.Module):
    
    def __init__(self, im_channels):
        super(Generator, self).__init__()
        
        
        self.net = nn.Sequential(
            nn.Conv2d(im_channels + 1, 64, 5, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(64),
            
            nn.Conv2d(64, 128, 3, stride=2, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            
            
            nn.Conv2d(128, 256, 3, stride=2, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            
            nn.Conv2d(256, 256, 3, stride=1, padding=2, dilation=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=4, dilation=4),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=8, dilation=8),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=16, dilation=16),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            
            nn.Conv2d(256, 256, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 256, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            
            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 128, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            
            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 32, 3, stride=1, padding=1),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, im_channels, 3, stride=1, padding=1)
            
        )

    def forward(self, X):
        out = self.net(X)
        return out
    
# g = Generator(2)
# g.eval()
# g(train[0][0].unsqueeze(0)).shape

"""# Paso 6: Paso 5: Implementación del Modelo Context-Encoder GAN(Local y Global Discriminador)"""

class LocalDiscriminator(nn.Module):
    def __init__(self, im_channels, region_size=16):
        super(LocalDiscriminator, self).__init__()
        
        self.region_size = region_size
        
        self.net = nn.Sequential(
            nn.Conv2d(im_channels + 1, 64, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 256, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 512, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(512),
            nn.Conv2d(512, 512, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(512),
            Flatten(),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.1),
            nn.BatchNorm1d(1024)
        )
        
    def forward(self, X, mask_bounds):
        
        local_regions = self._get_local_regions(X, mask_bounds)
        out = self.net(local_regions)
        
        return out
    
    def _get_local_regions(self, X, mask_bounds):

        N, ch, im_h, im_w = X.shape
        local_regions = torch.zeros((N, ch, self.region_size, self.region_size)).cuda()

        for i, bounds in enumerate(mask_bounds):
            y1, y2, x1, x2 = bounds
            
            ym, xm = (y1 + y2) // 2, (x1 + x2) // 2
            y1, x1 = ym - self.region_size // 2, xm - self.region_size // 2
            y2, x2 = y1 + self.region_size, x1 + self.region_size
            
            if y1 < 0:
                y1, y2 = 0, self.region_size
            elif y2 > im_h:
                y1, y2 = im_h - self.region_size, im_h
                
            if x1 < 0:
                x1, x2 = 0, self.region_size
            elif x2 > im_w:
                x1, x2 = im_w - self.region_size, im_w
            
            local_regions[i, :, :, :] = X[i, :, y1 : y2, x1 : x2]
        
        return local_regions

class GlobalDiscriminator(nn.Module):
    def __init__(self, im_channels):
        super(GlobalDiscriminator, self).__init__()
        
        self.net = nn.Sequential(
            nn.Conv2d(im_channels + 1, 64, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 256, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(256),
            nn.Conv2d(256, 512, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(512),
            nn.Conv2d(512, 512, 5, stride=2, padding=2),
            nn.LeakyReLU(0.1),
            nn.BatchNorm2d(512),
#             nn.Conv2d(512, 512, 5, stride=2, padding=2),
#             nn.LeakyReLU(0.1),
#             nn.BatchNorm2d(512),
            Flatten(),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.1),
            nn.BatchNorm1d(1024)
        )
        
    def forward(self, X):
        out = self.net(X)
        return out

class Discriminator(nn.Module):
    def __init__(self, local_d, global_d):
        super(Discriminator, self).__init__()
        self.local_discriminator = local_d
        self.global_discriminator = global_d
        self.fc = nn.Linear(2048, 1)
        
    def forward(self, X, mask_bounds):
        local_ = self.local_discriminator(X, mask_bounds)
        global_ = self.global_discriminator(X)
        concated = torch.cat((local_, global_), dim=1)
        out = self.fc(concated)
        
        return out

"""# Paso 7: Entrenamiento del Modelo"""

import time

def cycle(iterable):
    while True:
        for x in iterable:
            yield x

def train_gan(g, d, train, val, g_o, d_o, params, masks_fn):

    train_loader = data.DataLoader(train, batch_size=params['batch_size'], num_workers=0, pin_memory=True)
    val_loader = data.DataLoader(val, params['val_batch_size'], shuffle=True, pin_memory=True)
    val_loader = iter(cycle(val_loader))
    
    optimizer_g = g_o
    optimizer_d = d_o
    
    T_c, T_d = params['T_c'], params['T_d']
    w = params['w']
    for epoch in range(params['epochs']):
        ep_loss_g = 0.
        ep_loss_d = 0.
        fake_err = 0.
        real_err = 0.
        
        if epoch < T_c and epoch == 0:
                print(f'\n>>>> Training generator for {T_c} epochs.')

        if epoch < T_c + T_d and epoch == T_c:
                print(f'\n>>>> Training discriminator for {T_d} epochs.')
                
        if epoch == T_c + T_d:
                print(f'\n>>>> Training both generator and discriminator jointly.')
        
        start_time = time.time()
        
        g.train()
        d.train()
        for batch, _ in train_loader:
            
            N = batch.shape[0]
            batch = batch.cuda()
            
            masks_g, bounds_g = masks_fn(N)
            batch_masked = batch.clone() * (1 - masks_g)
            batch_with_masks = torch.cat((batch_masked, masks_g[:, :1]), dim=1)
            
            fake = g(batch_with_masks)
            
            loss_mse = (((batch - fake) * masks_g)**2).sum() / masks_g.sum()
            
            if epoch < T_c:
                loss_g = loss_mse
                loss_g.backward()
                optimizer_g.step()
                optimizer_g.zero_grad()
                ep_loss_g += loss_g.detach().cpu()
                continue
            else:
                inpainted = batch.clone()
                masks_byte = masks_g.byte()
                inpainted[masks_byte] = fake.detach()[masks_byte].view(-1)
                inpainted = torch.cat((inpainted, masks_g[:, :1]), dim=1)
                d_fake = d(inpainted.detach(), bounds_g)
                
                masks_d, bounds_d = masks_fn(N)
                real = torch.cat((batch.clone(), masks_d[:, :1]), dim=1)
                d_real = d(real, bounds_d)
                
                loss_d_fake = (d_fake**2).mean()
                loss_d_real = ((d_real - 1)**2).mean()
                loss_d = (loss_d_fake + loss_d_real) / 2
                loss_d.backward()
                optimizer_d.step()
                optimizer_d.zero_grad()

                if epoch >= T_c + T_d:
                    inpainted = batch.clone()
                    inpainted[masks_byte] = fake[masks_byte].view(-1)
                    inpainted = torch.cat((inpainted, masks_g[:, :1]), dim=1)
                    d_fake = d(inpainted, bounds_g)
                    loss_g = loss_mse + w * ((d_fake - 1)**2).mean()

                    loss_g.backward()
                    optimizer_g.step()
                    optimizer_g.zero_grad()

                    ep_loss_g += loss_g.detach().cpu()
                    
                ep_loss_d += loss_d.detach().cpu()
                fake_err += loss_d_fake.detach().cpu()
                real_err += loss_d_real.detach().cpu()
#             break
        
        if not T_c <= epoch < T_c + T_d:
            g.eval()
            val_batch = next(val_loader)[0].cuda()
            N, ch, _, _ = val_batch.shape
            
            masks, _ = masks_fn(N)
            val_batch_masked = val_batch * (1 - masks)
            val_batch_masked = torch.cat((val_batch_masked, masks[:, :1]), dim=1)
            val_pred = g(val_batch_masked).detach()
            val_loss = (((val_batch - val_pred) * masks)**2).sum() / masks.sum()
            inpainted = val_batch.clone()
            masks_byte = masks.byte()
            inpainted[masks_byte] = val_pred[masks_byte]
            imgs = [
                val_batch[0].cpu(), 
                masks[0].cpu(), 
                val_batch_masked[:, :-1][0].cpu(), 
                val_pred[0].cpu().clamp(0, 1), 
                inpainted[0].cpu()
            ]
            imshow(torch.cat(imgs, dim=2))
            plt.axis('off')
            plt.show()

        print('epoch: %d, g_loss: %0.4f, val_loss: %0.4f, d_loss: %0.4f, fake_err: %0.4f, real_err: %0.4f, time: %0.2f' %\
              (epoch, ep_loss_g, val_loss, ep_loss_d, fake_err, real_err, time.time() - start_time))

global_d = GlobalDiscriminator(im_channels=3).cuda()
local_d = LocalDiscriminator(im_channels=3, region_size=16).cuda()
discriminator = Discriminator(local_d=local_d, global_d=global_d).cuda()

generator = Generator(im_channels=3).cuda()

"""# Paso 8: Expermientación con visualización de nuestros resultados"""

train_params = {}
train_params['w'] = 0.0005
train_params['learning_rate_g'] = 0.0001
train_params['learning_rate_d'] = 0.00001
train_params['batch_size'] = 800
train_params['val_batch_size'] = 1024
train_params['T_c'] = 0
train_params['T_d'] = 0
train_params['epochs'] = 20 + train_params['T_c'] + train_params['T_d']

def gen_masks(N, ch=3):
    masks, bounds = create_hole_masks(N, 32, 32, (5, 12), (5, 12), same_size=False)
    return masks.repeat_interleave(ch, dim=1).cuda(), bounds

optimizer_g = optim.Adam(generator.parameters(), lr=train_params['learning_rate_g'])
optimizer_d = optim.Adam(discriminator.parameters(), lr=train_params['learning_rate_d'])

torch.cuda.empty_cache()
train_gan(generator, discriminator, train, val, optimizer_g, optimizer_d, train_params, gen_masks)

loss = 0
pixels = 0

model = generator
model.eval()
N = 512
test_loader = iter(data.DataLoader(test, N, shuffle=True, pin_memory=False))

for batch, _ in test_loader:
    masks, _ = gen_masks(batch.shape[0])
    batch_masked = batch.clone().cuda() * (1 - masks)
    batch_masked = torch.cat((batch_masked, masks[:, :1]), dim=1)
    pred = model(batch_masked).clamp(0, 1).detach()

    loss += (((batch.cuda() - pred) * masks)**2).sum().detach().cpu()
    pixels += masks.sum().detach().cpu()
    
print(loss / pixels)